# ä¿®å¤åŒ…å¯¼å…¥é”™è¯¯
import sys , os
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(base_dir)

import sys
import os
import asyncio
import json
from typing import AsyncGenerator, List, Dict, Any

import gradio as gr
from rich.console import Console
from rich.text import Text

from augmented.chat_openai import AsyncChatOpenAI
from augmented.agent import Agent
from augmented.mcp_client import MCPClient
from augmented.mcp_tools import PresetMcpTools
from augmented.utils.info import (
    PROJECT_ROOT_DIR,
    DEFAULT_MODEL_NAME
)
from augmented.utils import pretty

PRETTY_LOGGER = pretty.ALogger("[Agent]")


class State:
    def __init__(self):
        self.agent: Agent | None = None
        self.chat_history: List[List[str]] = []  # Gradioæ ¼å¼ï¼š[[user, assistant], ...]
        self.console = Console(record=True)


state = State()


async def init_agent_if_needed(model_name: str, base_url: str, api_key: str) -> Agent:
    """åˆå§‹åŒ– Agentï¼ˆä»…åœ¨é¦–æ¬¡æˆ–æ¨¡å‹å‚æ•°å˜åŒ–æ—¶ï¼‰"""
    if state.agent is None:
        mcp_clients = []
        for mcp_tool in [
            PresetMcpTools.filesystem.append_mcp_params(f" {PROJECT_ROOT_DIR!s}"),
            PresetMcpTools.fetch,
            PresetMcpTools.commander
        ]:
            mcp_client = MCPClient(**mcp_tool.to_common_params())
            mcp_clients.append(mcp_client)

        state.agent = Agent(
            model=model_name or DEFAULT_MODEL_NAME,
            mcp_clients=mcp_clients,
        )
        await state.agent.init()
        PRETTY_LOGGER.title("Agent åˆå§‹åŒ–å®Œæˆ")
    return state.agent


async def gradio_query(
        query: str,
        model_name: str,
        base_url: str,
        api_key: str,
        temperature: float,
        history: List[List[str]]
) -> AsyncGenerator[tuple[List[List[str]], str], None]:
    """
    æ”¹è¿›ç‰ˆï¼šå®Œå…¨åˆ†ç¦»å·¥å…·è°ƒç”¨å’Œå¯¹è¯å†…å®¹
    è¿”å›: (chat_history, tool_logs)
    """
    tool_logs = "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 50 + "\n"

    try:
        # 1. åˆå§‹åŒ– Agent
        agent = await init_agent_if_needed(model_name, base_url, api_key)
        tool_logs += "âœ… Agentåˆå§‹åŒ–å®Œæˆ\n\n"

        # 2. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²ï¼ˆä½†å…ˆä¸æ˜¾ç¤ºassistantå›å¤ï¼‰
        current_history = history.copy()
        current_history.append([query, ""])  # å ä½ï¼Œç­‰å¾…å›å¤
        yield current_history, tool_logs

        # 3. å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
        chat_resp = await agent.llm.chat(query)
        round_num = 0

        while True:
            round_num += 1
            tool_logs += f"ğŸ“ ç¬¬ {round_num} è½®å¤„ç†\n"
            yield current_history, tool_logs

            if chat_resp.tool_calls:
                # å·¥å…·è°ƒç”¨é˜¶æ®µ - åªåœ¨å·¦ä¾§æ˜¾ç¤ºè¯¦æƒ…
                for idx, tool_call in enumerate(chat_resp.tool_calls, 1):
                    tool_logs += f"  ğŸ› ï¸ å·¥å…· {idx}: {tool_call.function.name}\n"
                    tool_logs += f"     å‚æ•°: {tool_call.function.arguments}\n"
                    yield current_history, tool_logs

                    # æ‰§è¡Œå·¥å…·
                    target_mcp_client = next(
                        (c for c in agent.mcp_clients
                         if tool_call.function.name in [t.name for t in c.get_tools()]),
                        None
                    )

                    if target_mcp_client:
                        mcp_result = await target_mcp_client.call_tool(
                            tool_call.function.name,
                            json.loads(tool_call.function.arguments),
                        )
                        result_preview = str(mcp_result)[:200] + "..." if len(str(mcp_result)) > 200 else str(
                            mcp_result)
                        tool_logs += f"     âœ… ç»“æœ: {result_preview}\n\n"
                        yield current_history, tool_logs

                        agent.llm.append_tool_result(tool_call.id, mcp_result.model_dump_json())
                    else:
                        tool_logs += f"     âŒ é”™è¯¯: å·¥å…·æœªæ‰¾åˆ°\n\n"
                        yield current_history, tool_logs
                        return

                # ç»§ç»­ä¸‹ä¸€è½®
                chat_resp = await agent.llm.chat()
            else:
                # æœ€ç»ˆå“åº”é˜¶æ®µ - æ›´æ–°å³ä¾§å¯¹è¯å†å²
                final_response = chat_resp.content
                current_history[-1][1] = final_response  # å¡«å……assistantå›å¤
                tool_logs += f"âœ… å¤„ç†å®Œæˆï¼Œå…± {round_num} è½®\n"
                yield current_history, tool_logs
                break

    except Exception as e:
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
        tool_logs += f"\n{error_msg}\n"
        if current_history and current_history[-1][1] == "":
            current_history[-1][1] = error_msg
        yield current_history, tool_logs


def clear_history():
    """æ¸…ç©ºå¯¹è¯å†å²"""
    return [], "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 50 + "\nå·²æ¸…ç©ºå†å²\n"


def reset_agent():
    """é‡ç½®Agent"""
    global state
    if state.agent:
        # è¿™é‡Œå¯ä»¥æ·»åŠ cleanupé€»è¾‘
        state.agent = None
    return [], "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 50 + "\nå·²é‡ç½®Agent\n"


# Gradio ç•Œé¢
with gr.Blocks(title="Schneider Agent äº¤äº’ç•Œé¢", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# Schneider Agent äº¤äº’å¹³å°")
    gr.Markdown("å·¦ä¾§æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¯¦æƒ…ï¼Œå³ä¾§æ˜¾ç¤ºå¯¹è¯å†…å®¹ï¼Œæ”¯æŒå¤šè½®è¿ç»­å¯¹è¯")

    with gr.Row():
        # å·¦ä¾§ï¼šé…ç½® + å·¥å…·æ—¥å¿—
        with gr.Column(scale=1):
            gr.Markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
            model_name = gr.Textbox(
                label="æ¨¡å‹åç§°",
                value=DEFAULT_MODEL_NAME,
                placeholder="å¦‚: gpt-4, claude-3-5-sonnet"
            )
            base_url = gr.Textbox(
                label="API åœ°å€",
                value=os.environ.get("OPENAI_BASE_URL", ""),
                placeholder="å¦‚: https://api.openai.com/v1"
            )
            api_key = gr.Textbox(
                label="API Key",
                type="password",
                value=os.environ.get("OPENAI_API_KEY", ""),
                placeholder="è¾“å…¥ä½ çš„APIå¯†é’¥"
            )
            temperature = gr.Slider(
                label="æ¸©åº¦",
                minimum=0.0,
                maximum=1.0,
                value=0.1,
                step=0.1
            )

            with gr.Row():
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", size="sm")
                reset_btn = gr.Button("ğŸ”„ é‡ç½®Agent", size="sm")

            # å·¥å…·è°ƒç”¨æ—¥å¿—åŒºåŸŸ
            tool_status = gr.Textbox(
                label="ğŸ”§ å·¥å…·è°ƒç”¨è¯¦æƒ…",
                value="ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 50 + "\nç­‰å¾…æŸ¥è¯¢...\n",
                lines=15,
                max_lines=20,
                interactive=False,
                show_copy_button=True
            )

        # å³ä¾§ï¼šå¯¹è¯åŒºåŸŸ
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ’¬ å¯¹è¯å†å²")

            # ä½¿ç”¨Chatbotç»„ä»¶æ˜¾ç¤ºå¯¹è¯å†å²
            chatbot = gr.Chatbot(
                value=[],
                height=400,
                show_copy_button=True,
                bubble_full_width=False,
                show_share_button=False
            )

            # è¾“å…¥åŒºåŸŸ
            with gr.Row():
                msg_input = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜...",
                    scale=4,
                    show_label=False
                )
                send_btn = gr.Button("ğŸš€ å‘é€", scale=1, variant="primary")

            gr.Markdown("ğŸ’¡ **æç¤º**: æ”¯æŒå¤šè½®å¯¹è¯ï¼Œå·¥å…·è°ƒç”¨è¯¦æƒ…ä¼šæ˜¾ç¤ºåœ¨å·¦ä¾§")

    # ç»‘å®šäº‹ä»¶
    send_btn.click(
        fn=gradio_query,
        inputs=[msg_input, model_name, base_url, api_key, temperature, chatbot],
        outputs=[chatbot, tool_status]
    ).then(
        lambda: "",  # æ¸…ç©ºè¾“å…¥æ¡†
        outputs=[msg_input]
    )

    # å›è½¦å‘é€
    msg_input.submit(
        fn=gradio_query,
        inputs=[msg_input, model_name, base_url, api_key, temperature, chatbot],
        outputs=[chatbot, tool_status]
    ).then(
        lambda: "",
        outputs=[msg_input]
    )

    # æ¸…ç©ºå’Œé‡ç½®æŒ‰é’®
    clear_btn.click(
        fn=clear_history,
        outputs=[chatbot, tool_status]
    )

    reset_btn.click(
        fn=reset_agent,
        outputs=[chatbot, tool_status]
    )

if __name__ == "__main__":
    demo.queue().launch(
        server_name="localhost",
        server_port=9999,
        auth=("zhangsan", "123456"),
        share=False,
        debug=True
    )