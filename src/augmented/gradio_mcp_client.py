# ä¿®å¤åŒ…å¯¼å…¥é”™è¯¯
import sys, os

base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(base_dir)

import sys
import os
import asyncio
import json
from typing import AsyncGenerator, List, Dict, Any

import gradio as gr
from rich.console import Console
from rich.text import Text

from augmented.chat_openai import AsyncChatOpenAI
from augmented.agent import Agent
from augmented.mcp_client import MCPClient
from augmented.mcp_tools import PresetMcpTools
from augmented.utils.info import (
    PROJECT_ROOT_DIR,
    DEFAULT_MODEL_NAME
)
from augmented.utils import pretty

PRETTY_LOGGER = pretty.ALogger("[Agent]")


class State:
    def __init__(self):
        self.agent: Agent | None = None
        self.chat_history: List[List[str]] = []  # Gradioæ ¼å¼ï¼š[[user, assistant], ...]
        self.console = Console(record=True)


state = State()


async def init_agent_if_needed(model_name: str, base_url: str, api_key: str) -> Agent:
    """åˆå§‹åŒ– Agentï¼ˆä»…åœ¨é¦–æ¬¡æˆ–æ¨¡å‹å‚æ•°å˜åŒ–æ—¶ï¼‰"""
    if state.agent is None:
        mcp_clients = []
        for mcp_tool in [
            PresetMcpTools.filesystem.append_mcp_params(f" {PROJECT_ROOT_DIR!s}"),
            PresetMcpTools.fetch,
            PresetMcpTools.commander
        ]:
            mcp_client = MCPClient(**mcp_tool.to_common_params())
            mcp_clients.append(mcp_client)

        state.agent = Agent(
            model=model_name or DEFAULT_MODEL_NAME,
            mcp_clients=mcp_clients,
        )
        await state.agent.init()
        PRETTY_LOGGER.title("Agent åˆå§‹åŒ–å®Œæˆ")
    return state.agent


async def gradio_query(
        query: str,
        model_name: str,
        base_url: str,
        api_key: str,
        temperature: float,
        history: List[List[str]]
) -> AsyncGenerator[tuple[List[List[str]], str], None]:
    """
    æ”¹è¿›ç‰ˆï¼šæ”¯æŒæµå¼è¾“å‡ºå’Œå®Œæ•´å·¥å…·è°ƒç”¨æ—¥å¿—
    è¿”å›: (chat_history, tool_logs)
    """
    tool_logs = "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 80 + "\n"

    try:
        # 1. åˆå§‹åŒ– Agent
        agent = await init_agent_if_needed(model_name, base_url, api_key)
        tool_logs += "âœ… Agentåˆå§‹åŒ–å®Œæˆ\n\n"

        # 2. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        current_history = history.copy()
        current_history.append([query, ""])  # å ä½ï¼Œç­‰å¾…å›å¤
        yield current_history, tool_logs

        # 3. å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
        chat_resp = await agent.llm.chat(query)
        round_num = 0

        while True:
            round_num += 1
            tool_logs += f"ğŸ“ ç¬¬ {round_num} è½®å¤„ç†\n"
            tool_logs += f"{'â”€' * 50}\n"
            yield current_history, tool_logs

            if chat_resp.tool_calls:
                # å·¥å…·è°ƒç”¨é˜¶æ®µ - æ˜¾ç¤ºå®Œæ•´è¯¦æƒ…
                tool_logs += f"ğŸ› ï¸ æ£€æµ‹åˆ° {len(chat_resp.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨\n\n"

                for idx, tool_call in enumerate(chat_resp.tool_calls, 1):
                    tool_logs += f"ã€å·¥å…· {idx}ã€‘{tool_call.function.name}\n"

                    # æ ¼å¼åŒ–å‚æ•°æ˜¾ç¤º
                    try:
                        args = json.loads(tool_call.function.arguments)
                        formatted_args = json.dumps(args, indent=2, ensure_ascii=False)
                        tool_logs += f"å‚æ•°:\n{formatted_args}\n"
                    except:
                        tool_logs += f"å‚æ•°: {tool_call.function.arguments}\n"

                    yield current_history, tool_logs

                    # æ‰§è¡Œå·¥å…·
                    target_mcp_client = next(
                        (c for c in agent.mcp_clients
                         if tool_call.function.name in [t.name for t in c.get_tools()]),
                        None
                    )

                    if target_mcp_client:
                        tool_logs += "â³ æ‰§è¡Œä¸­...\n"
                        yield current_history, tool_logs

                        mcp_result = await target_mcp_client.call_tool(
                            tool_call.function.name,
                            json.loads(tool_call.function.arguments),
                        )

                        # æ˜¾ç¤ºå®Œæ•´ç»“æœ
                        result_str = str(mcp_result)
                        if len(result_str) > 1000:
                            tool_logs += f"âœ… ç»“æœ (å‰1000å­—ç¬¦):\n{result_str[:1000]}\n...[ç»“æœå¤ªé•¿å·²æˆªæ–­]\n\n"
                        else:
                            tool_logs += f"âœ… ç»“æœ:\n{result_str}\n\n"
                        yield current_history, tool_logs

                        agent.llm.append_tool_result(tool_call.id, mcp_result.model_dump_json())
                    else:
                        tool_logs += f"âŒ é”™è¯¯: å·¥å…· '{tool_call.function.name}' æœªæ‰¾åˆ°\n\n"
                        yield current_history, tool_logs
                        return

                # ç»§ç»­ä¸‹ä¸€è½®
                tool_logs += "ğŸ”„ ç»§ç»­å¤„ç†...\n\n"
                yield current_history, tool_logs
                chat_resp = await agent.llm.chat()
            else:
                # æœ€ç»ˆå“åº”é˜¶æ®µ - æµå¼æ˜¾ç¤º
                final_response = chat_resp.content
                tool_logs += f"âœ… ç”Ÿæˆæœ€ç»ˆå›å¤ ({len(final_response)} å­—ç¬¦)\n"
                tool_logs += f"{'=' * 80}\n"
                tool_logs += f"æ€»è®¡ {round_num} è½®å¤„ç†å®Œæˆ\n"

                # æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ
                current_text = ""
                words = final_response.split()

                for i, word in enumerate(words):
                    current_text += word + " "
                    current_history[-1][1] = current_text.strip()
                    yield current_history, tool_logs

                    # æ§åˆ¶è¾“å‡ºé€Ÿåº¦ï¼Œè®©æ•ˆæœæ›´è‡ªç„¶
                    if i % 3 == 0:  # æ¯3ä¸ªè¯æš‚åœä¸€ä¸‹
                        await asyncio.sleep(0.05)

                # ç¡®ä¿æœ€ç»ˆæ–‡æœ¬å®Œæ•´
                current_history[-1][1] = final_response
                yield current_history, tool_logs
                break

    except Exception as e:
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
        tool_logs += f"\n{error_msg}\n"
        tool_logs += f"é”™è¯¯è¯¦æƒ…: {repr(e)}\n"
        if current_history and current_history[-1][1] == "":
            current_history[-1][1] = error_msg
        yield current_history, tool_logs


def clear_history():
    """æ¸…ç©ºå¯¹è¯å†å²"""
    return [], "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 80 + "\nâœ¨ å†å²å·²æ¸…ç©ºï¼Œå¯ä»¥å¼€å§‹æ–°å¯¹è¯\n"


def reset_agent():
    """é‡ç½®Agent"""
    global state
    if state.agent:
        # è¿™é‡Œå¯ä»¥æ·»åŠ cleanupé€»è¾‘
        state.agent = None
    return [], "ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 80 + "\nğŸ”„ Agentå·²é‡ç½®ï¼Œä¸‹æ¬¡æŸ¥è¯¢å°†é‡æ–°åˆå§‹åŒ–\n"


# Gradio ç•Œé¢
with gr.Blocks(title="Schneider Agent äº¤äº’ç•Œé¢", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– Schneider Agent äº¤äº’å¹³å°")

    with gr.Row():
        # å·¦ä¾§ï¼šå·¥å…·æ—¥å¿— + é…ç½®ï¼ˆç´§å‡‘å¸ƒå±€ï¼‰
        with gr.Column(scale=1, min_width=400):
            # å·¥å…·è°ƒç”¨æ—¥å¿—åŒºåŸŸ - å ä¸»è¦ç©ºé—´
            tool_status = gr.Textbox(
                label="ğŸ”§ å·¥å…·è°ƒç”¨è¯¦æƒ…",
                value="ğŸ”§ å·¥å…·è°ƒç”¨æ—¥å¿—\n" + "=" * 80 + "\nğŸ’¡ ç­‰å¾…æŸ¥è¯¢ï¼Œå·¥å…·è°ƒç”¨è¯¦æƒ…å°†åœ¨æ­¤æ˜¾ç¤º...\n",
                lines=20,
                max_lines=25,
                interactive=False,
                show_copy_button=True,
                container=True
            )

            # é…ç½®åŒºåŸŸ - å¯æŠ˜å ï¼Œç´§å‡‘æ˜¾ç¤º
            with gr.Accordion("âš™ï¸ æ¨¡å‹é…ç½®", open=False):
                with gr.Row():
                    model_name = gr.Textbox(
                        label="æ¨¡å‹",
                        value=DEFAULT_MODEL_NAME,
                        placeholder="gpt-4",
                        scale=2
                    )
                    temperature = gr.Slider(
                        label="æ¸©åº¦",
                        minimum=0.0,
                        maximum=1.0,
                        value=0.1,
                        step=0.1,
                        scale=1
                    )

                base_url = gr.Textbox(
                    label="APIåœ°å€",
                    value=os.environ.get("OPENAI_BASE_URL", ""),
                    placeholder="https://api.openai.com/v1",
                    lines=1
                )
                api_key = gr.Textbox(
                    label="API Key",
                    type="password",
                    value=os.environ.get("OPENAI_API_KEY", ""),
                    placeholder="è¾“å…¥APIå¯†é’¥",
                    lines=1
                )

                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", size="sm", scale=1)
                    reset_btn = gr.Button("ğŸ”„ é‡ç½®", size="sm", scale=1)

        # å³ä¾§ï¼šå¯¹è¯åŒºåŸŸï¼ˆå ä¸»è¦ç©ºé—´ï¼‰
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ’¬ å¯¹è¯åŒºåŸŸ")

            # å¯¹è¯å†å²æ˜¾ç¤º
            chatbot = gr.Chatbot(
                value=[],
                height=300,
                show_copy_button=True,
                bubble_full_width=False,
                show_share_button=False,
                avatar_images=None,
                container=True
            )

            # è¾“å…¥åŒºåŸŸ
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="ğŸ’¬ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæ”¯æŒå¤šè½®å¯¹è¯...",
                    scale=5,
                    show_label=False,
                    lines=1,
                    max_lines=3
                )
                send_btn = gr.Button("ğŸš€ å‘é€", scale=1, variant="primary")

    # åº•éƒ¨æç¤º
    gr.Markdown("""
    <div style='text-align: center; color: #666; font-size: 12px; margin-top: 10px;'>
    ğŸ’¡ <b>ä½¿ç”¨æç¤º</b>: æ”¯æŒè¿ç»­å¯¹è¯ | å·¥å…·è°ƒç”¨è¯¦æƒ…å®æ—¶æ˜¾ç¤ºåœ¨å·¦ä¾§ | å›å¤æ”¯æŒæµå¼è¾“å‡º
    </div>
    """)

    # ç»‘å®šäº‹ä»¶
    send_btn.click(
        fn=gradio_query,
        inputs=[msg_input, model_name, base_url, api_key, temperature, chatbot],
        outputs=[chatbot, tool_status]
    ).then(
        lambda: "",  # æ¸…ç©ºè¾“å…¥æ¡†
        outputs=[msg_input]
    )

    # å›è½¦å‘é€
    msg_input.submit(
        fn=gradio_query,
        inputs=[msg_input, model_name, base_url, api_key, temperature, chatbot],
        outputs=[chatbot, tool_status]
    ).then(
        lambda: "",
        outputs=[msg_input]
    )

    # æ¸…ç©ºå’Œé‡ç½®æŒ‰é’®
    clear_btn.click(
        fn=clear_history,
        outputs=[chatbot, tool_status]
    )

    reset_btn.click(
        fn=reset_agent,
        outputs=[chatbot, tool_status]
    )

if __name__ == "__main__":
    demo.queue().launch(
        server_name="localhost",
        server_port=9999,
        auth=("zhangsan", "123456"),
        share=False,
        debug=True
    )